# Also, make sure that all from major albumreleases are included and others are excluded (didn't seem to be the case for some reason)
# Load required code libraries
library(cluster)
library(tm)
library(LSAfun)
library(lsa)
dir = 'C:/Users/caleb/OneDrive/Caleb/Personal/Financials/Curriculum Vitae/Blog'
setwd(dir)
# Create text matrix using tm's DirSource.
# Create corpus in memory
# There's some mistyped code that doesn't work in this paper
# raw_corpus<-VCorpus(source_dir,readerControl-list(language='en'))
#I'll copy and paste from previous example to create a raw corpus
# Establish source directory for all text files. (one .txt file = 1 song)
source_dir<-paste0(dir,"/AFIsongs/")
data(stopwords_en)
# Create TDM (text document matrix) with each txt file equal to one document
TDM<-textmatrix(source_dir,stopwords=c(stopwords_en),stemming=TRUE,
removeNumber=F,minGlobFreq=1.75)
# TDM #  view TDM
TDM_summary<-summary.textmatrix(TDM)
TDM_summary_terms<-t(TDM_summary["vocabulary"])
TDM_summary_docs<-t(TDM_summary["documents"])
# Before running the SVM, create a weighted matrix TDM2.
# TDM2 is term frequency x inverse document frequency (this is a standard method)
# lw = local weighting, more importance to terms that appear more times within a single document
# gw = global weighting, less importance to w9rds that appear in more document (same reasoning as removing stop words)
TDM2 <-lw_tf(TDM)*gw_idf(TDM)
# TDM2
#| include: false
#| echo: false
library(cluster)
library(tm)
library(LSAfun)
library(lsa)
# Run LSA on wegihted matrix TDM2.
# Number of dimensions chosen by default with dimcalc_share()
# lsa transformed TDM2 into three matrices and placed them all into the miniLSAspace object
# tk = term matrix, dk = document matrix, and sk = singular value matrix
miniLSAspace<-lsa(TDM2,dims=dimcalc_share())
# View matrix by transforming SVD matrix into text matrix
# as.textmatrix(miniLSAspace)
# Doesn't work.  Needs other non-working script.
# findFreqTerms(TDM2)
# these are all unrotated "loadings", like PCA or factor analysis
# This command will show the value-weighted matrix of Terms
# factoring of terms, # factors = 40, so there are 40 factors with loadings for each term
tk2=t(miniLSAspace$sk*t(miniLSAspace$tk))
# round(tk2,2)
#DT::datatable(round(tk2,2),
#              fillContainer=TRUE)
#| include: false
#| echo: false
# This will show the matrix of documents
# factoring of documents, # factors = 40, so there are 40 factors with loadings for each documents
dk2 = miniLSAspace$dk
# round(dk2,2)
#DT::datatable(round(dk2,2),
#              fillContainer = TRUE)
#| include: false
#| echo: false
# The sk matrix of singular values connects tk and dk matrices to reproduce the the original TDM2
# Because the sk matrix only has diagonal values, R stores it as a numeric vector
sk2 = miniLSAspace$sk
# round(sk2,2)
#| echo: false
#| freeze: false
#| include: true
#| cache: true
myTerms2<-rownames(tk2)
myCosineSpace2<-multicos(myTerms2,tvectors=tk2) # removed breakdown=TRUE arg, and it worked
DT::datatable(round(myCosineSpace2,2),
options=list(scrollX=TRUE),
caption="Table 3: Cosine similarity for relationships between individual words.")
#| echo: false
#| freeze: false
#| include: true
#| cache: true
# STep 2: Analyzing the Semantic Space
# assumes that miniLSAspace has been created
# Now we will calculate cosine similarity
myDocs<-rownames(dk2)
# round(myCosineSpace2,2)
# DT::datatable(round(myCosineSpace2,2))
# Can create cosine space for documents as well
myCosineSpace3<-multicos(myDocs,tvectors=dk2)
DT::datatable(round(myCosineSpace3,2),
options=list(scrollX=TRUE,scrollY=TRUE),
caption="Table 4: Cosine similarity table for relationships between songs.")
#| echo: false
#| include: true
# plot wordcloud using lsa results!!!
Term_count<-apply(TDM2,1,sum)
TCT<-t(Term_count)
suppressWarnings(wordcloud(myTerms2,TCT,min.freq=3,random.order=FALSE,color=brewer.pal(8,"Dark2")
,scale=c(3.5,.1)))
#| include: true
#| echo: false
#| fig-cap: "Figure 3: Heatmap of the word FEEL and its relation to top 20 words in latent semantic space."
# Show words on a heat map (authors say this is a compelling visualization)
# Extract the closet words to "death" (a list of their distances as a named vector)
words<-neighbors("feel",n=20,tvectors=tk2[,1:ncol(tk2)])
# Extract the actual words, and find the distances in the space
myCosineSpace2<-multicos(names(words),tvectors=tk2[,1:ncol(tk2)])
col<-colorRampPalette(brewer.pal(9,"RdYlGn"))(256)
heatmap.2(myCosineSpace2,col=col)
ht1<-Heatmap(myCosineSpace2,col=col)
#| include: true
#| echo: false
# Extract the closet words to "birth" (a list of their distances as a named vector)
words<-neighbors("love",n=20,tvectors=tk2[,1:ncol(tk2)])
# Extract the actual words, and find the distances in the space
myCosineSpace2<-multicos(names(words),tvectors=tk2[,1:ncol(tk2)])
col<-colorRampPalette(brewer.pal(9,"RdYlGn"))(256)
heatmap.2(myCosineSpace2,col=col)
ht2<-Heatmap(myCosineSpace2,col=col)
DT::datatable(round(tk2,2),
fillContainer=TRUE)
t(tk2)
# View matrix by transforming SVD matrix into text matrix
as.textmatrix(miniLSAspace)
# Run LSA on wegihted matrix TDM2.
# Number of dimensions chosen by default with dimcalc_share()
# lsa transformed TDM2 into three matrices and placed them all into the miniLSAspace object
# tk = term matrix, dk = document matrix, and sk = singular value matrix
miniLSAspace<-lsa(TDM2,dims=dimcalc_share())
library(lsa)
# Run LSA on wegihted matrix TDM2.
# Number of dimensions chosen by default with dimcalc_share()
# lsa transformed TDM2 into three matrices and placed them all into the miniLSAspace object
# tk = term matrix, dk = document matrix, and sk = singular value matrix
miniLSAspace<-lsa(TDM2,dims=dimcalc_share())
# View matrix by transforming SVD matrix into text matrix
as.textmatrix(miniLSAspace)
# Doesn't work.  Needs other non-working script.
findFreqTerms(TDM2)
# Doesn't work.  Needs other non-working script.
findFreqTerms(miniLSAspace)
# Doesn't work.  Needs other non-working script.
findFreqTerms(miniLSAspace)
# these are all unrotated "loadings", like PCA or factor analysis
# This command will show the value-weighted matrix of Terms
# factoring of terms, # factors = 40, so there are 40 factors with loadings for each term
tk2=t(miniLSAspace$sk*t(miniLSAspace$tk))
round(tk2,2)
tk2_round<-round(tk2,2)
tk2_round |> top_n()
tk2_round %>% top_n()
tk2_round %>% gather() %>$ top_n()
View(tk2_round)
tk2_round %>% slice_max(n=5)
as.data.frame(tk2_round) %>% slice_max(n=5)
tk2_round_df<-as.data.frame(tk2_round)
tk2_round_df
tk2_round_df %>% slice_max(order_by=row.names(tk2_round_df),n=5)
tk2_round_df %>% lapply(1:ncol(.),function(x) slice_max(order_by=.[,x]),n=10)
lapply(1:ncol(tk2_round_df),function(x) slice_max(order_by=tk2_round_df[,x]),n=10)
lapply(1:ncol(tk2_round_df),function(x) {
slice_max(order_by=tk2_round_df[,x],n=10)}
)
sapply(1:ncol(tk2_round_df),function(x) {
slice_max(order_by=tk2_round_df[,x],n=10)}
)
sapply(1:ncol(tk2_round_df),function(x) {
top_n(order_by=tk2_round_df[,x])}
)
sapply(1:ncol(tk2_round_df),function(x) {
top_n(tk2_round_df[,x])}
)
sapply(1:ncol(tk2_round_df),function(x) {
top_n(as.numeric(tk2_round_df[,x]))}
)
sapply(1:ncol(tk2_round_df),function(x) {
top_n(as.float(tk2_round_df[,x]))}
)
sapply(1:ncol(tk2),function(x) {
top_n(tk2[,x])}
)
str(tk2)
str(tk2_round_df)
str(tk2_round_df[,1])
str(tk2_round_df[,3])
sapply(1:ncol(tk2_round_df),function(x) {
max(tk2_round_df[,x])}
)
sapply(1:ncol(tk2_round_df),function(x) {
slice_max(tk2_round_df[,x])}
)
sapply(1:ncol(tk2_round_df),function(x) {
max(tk2_round_df[,x])
print(row.names(max(tk2_round_df[,x])))}
)
row.names(max(tk2_round_df[,1]
row.names(max(tk2_round_df[,1]))
max(tk2_round_df[,1])
sapply(1:ncol(tk2_round_df),function(x) {
max.col(tk2_round_df[x,])
print(row.names(max(tk2_round_df[,x])))}
)
max.col(tk2_round_df)
rownames(tk2_round_df)[max.col(tk2_round_df)]
newdf<-data.frame()
newdf$max<-max.col(tk2_round_df)
newdf$word<-row.names(max.col(tk2_round_df))
View(newdf)
newdf$max<-""
newdf<-data.frame("word"="",
"max"="")
newdf$max<-max.col(tk2_round_df)
max<-max.col(tk2_round_df)
newdf$max<-max
newdf$max<-as.numeric(max)
sapply(tk2_round_df,function(x) head(row.names(tk2_round_df)[order(x),decreasing=TRUE],10))
sapply(tk2_round_df,function(x) head(row.names(tk2_round_df)[order(x),decreasing=TRUE],33))
sapply(tk2_round_df,function(x) head(row.names(tk2_round_df)[order(x),decreasing=TRUE],ncol(tk2_round_df)))
head(tk2_round_df)(row.names(tk2_round_df)[order(tk2_round_df),decreasing=TRUE]),2)
head(row.names(tk2_round_df)[order(tk2_round_df),decreasing=TRUE]),2)
head(row.names(tk2_round_df)[order(tk2_round_df,decreasing=TRUE)],2)
sapply(tk2_round_df,function(x) head(row.names(tk2_round_df)[order(tk2_round_df,decreasing=TRUE)],2))
sapply(tk2_round_df,function(x) head(row.names(tk2_round_df)[order(x,decreasing=TRUE)],2))
sapply(tk2_round_df,function(x) head(row.names(tk2_round_df)[order(x,decreasing=TRUE)],10))
sapply(tk2_round_df,function(x) head(tk2_round_df[order(x,decreasing=TRUE)],10))
sapply(tk2_round_df,function(x) head(x[order(x,decreasing=TRUE)],10))
newdf$word<-sapply(tk2_round_df,function(x) head(row.names(tk2_round_df)[order(x,decreasing=TRUE)],10))
word<-sapply(tk2_round_df,function(x) head(row.names(tk2_round_df)[order(x,decreasing=TRUE)],10))
value<-sapply(tk2_round_df,function(x) head(x[order(x,decreasing=TRUE)],10))
rbind(word,value)
cbind(word,value)
newdf<-cbind(word,value)
word<-sapply(tk2_round_df,function(x) head(row.names(tk2_round_df)[order(x,decreasing=TRUE)],5))
value<-sapply(tk2_round_df,function(x) head(x[order(x,decreasing=TRUE)],5))
top_themes<-cbind(word,value)
DT::datatable(top_themes,
fillContainer=TRUE)
DT::datatable(top_themes,
fillContainer=TRUE)
dim(tk2)
install.packages('textmineR')
install.packages('textmineR')
# https://cran.r-project.org/web/packages/textmineR/vignettes/c_topic_modeling.html
library(textmineR)
tf_sample<-TermDocFreq(TDM2)
tf_sample
#create dtm
dtm<-CreateDTM(TDM2)
# https://cran.r-project.org/web/packages/textmineR/vignettes/c_topic_modeling.html
library(textmineR)
#create dtm
dtm<-CreateDtm(TDM2)
#create dtm
dtm<-CreateDtm(TDM)
tf_sample<-TermDocFreq(TDM)
tf_sample
lsa_model<-FitLsaModel(TDM2)
lsa_model<-FitLsaModel(TDM)
#create dtm
dtm<-CreateDtm(TDM2)
str(TDM2)
summary(miniLSAspace)
summary(miniLSAspace$tk)
View(tk2)
coherence(myCosineSpace2)
library(LSAfun)
library(LSAfun)
coherence(myCosineSpace2)
coherence(myTerms2,tvectors=tk2)
coherence(myDocs,tvectors=tk2)
coherence(myTerms2,tvectors=tk2)
# https://www.tidytextmining.com/topicmodeling.html
library(topicmodels)
install.packages('topicmodels')
TDM2
LDA(TDM2),k=2,control=list(seed=1234)
LDA(TDM2,k=2,control=list(seed=1234)
lda<-LDA(TDM2,k=2,control=list(seed=1234))
# https://www.tidytextmining.com/topicmodeling.html
library(topicmodels)
lda<-LDA(TDM2,k=2,control=list(seed=1234))
lda<-LDA(TDM,k=2,control=list(seed=1234))
lda
lda_topics<-tidy(lda,matrix="beta")
install.packages('tidytext')
library(tidytext)
lda_topics<-tidy(lda,matrix="beta")
library(tidyverse)
lda_topics<-tidy(lda,matrix="beta")
install.packages('reshape2')
library(reshape2)
lda<-LDA(TDM,k=2,control=list(seed=1234))
library(tidytext)
library(tidytext)
library(reshape2)
lda_topics<-tidy(lda,matrix="beta")
library(ggplot2)
library(dplyr)
lda_top_terms<-lda_topics %>%
group_by(topic) %>%
slice_max(beta,n=10) %>%
ungroup() %>%
arrange(topic,-beta)
lda_top_terms %>%
mutate(term=reorder)within(term,beta,topic)) %>%
lda_top_terms %>%
mutate(term=reorder_within(term,beta,topic)) %>%
ggplot(aes(beta,term,fill=factor(topic))) +
geom_col(show.legend=FALSE) +
face_wrap(~ topic, scales = "free") +
scale_y_reordered()
lda_top_terms %>%
mutate(term=reorder_within(term,beta,topic)) %>%
ggplot(aes(beta,term,fill=factor(topic))) +
geom_col(show.legend=FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
lda<-LDA(TDM2,k=2,control=list(seed=1234))
TDM
TDM2
lda<-LDA(TDM2$matrix,k=2,control=list(seed=1234))
cast_dtm(TDM@)
cast_dtm(TDM2)
cast_dtm(TDM)
cast_dfm(TDM)
cast(TDM)
View(tidyLyrics_select)
lda<-LDA(tidyLyrics_select,k=2,control=list(seed=1234))
lda<-LDA(data.frame(tidyLyrics_select,na.rm=TRUE),k=2,control=list(seed=1234))
View(allLyricsTokenised)
View(allLyricscount)
View(allLyrics2)
View(allLyricsTokenised)
View(tidyLyrics)
View(tidyLyrics)
View(tidyLyricscount)
tidyLyrics
tidyLyrics_select<-tidyLyrics %>%
select(album,song_name,word) # song name and word
AFI_songs_df_split<- split(tidyLyrics_select,tidyLyrics_select$song_name)
names(AFI_songs_df_split)[89]<-"Prelude 12 21"
AFI_songs_df_split[['Prelude 12 21']][1]<-"Prelude 12 21"
plot_tidyLyrics<-tidyLyrics_select %>%
bind_tf_idf(word,album,n) %>%
mutate(album=factor(album,levels=album_major_release))
tidyLyrics_select
View(tidyLyrics)
View(tidyLyricscount)
View(tidyLyrics)
tidyLyricscount<-tidyLyrics %>%
count(word,album, sort = TRUE)
DT::datatable(tidyLyricscount,
caption = "Table 2: Word frequency across all of AFI's major album releases (with stop-words removed).",
colnames=c("Word","Frequency")
#             options = list(
# initComplete = JS(
#   "function(settings, json) {",
#   "$(this.api().table().header()).css({'background-color': '#92141c', 'color': '#767975'});",
#   "}")
)
tidyLyricscount<-tidyLyrics %>%
count(album,word, sort = TRUE)
DT::datatable(tidyLyricscount,
caption = "Table 2: Word frequency across all of AFI's major album releases (with stop-words removed).",
colnames=c("Word","Frequency")
#             options = list(
# initComplete = JS(
#   "function(settings, json) {",
#   "$(this.api().table().header()).css({'background-color': '#92141c', 'color': '#767975'});",
#   "}")
)
DT::datatable(tidyLyricscount,
caption = "Table 2: Word frequency across all of AFI's major album releases (with stop-words removed).",
colnames=c("Word","Frequency")
#             options = list(
# initComplete = JS(
#   "function(settings, json) {",
#   "$(this.api().table().header()).css({'background-color': '#92141c', 'color': '#767975'});",
#   "}")
)
View(tidyLyricscount)
DT::datatable(tidyLyricscount,
caption = "Table 2: Word frequency across all of AFI's major album releases (with stop-words removed).",
colnames=c("index","Album","Word","Frequency")
#             options = list(
# initComplete = JS(
#   "function(settings, json) {",
#   "$(this.api().table().header()).css({'background-color': '#92141c', 'color': '#767975'});",
#   "}")
)
tidyLyricscount<-tidyLyrics %>%
count(word, sort = TRUE)
DT::datatable(tidyLyricscount,
caption = "Table 2: Word frequency across all of AFI's major album releases (with stop-words removed).",
colnames=c("Word","Frequency")
#             options = list(
# initComplete = JS(
#   "function(settings, json) {",
#   "$(this.api().table().header()).css({'background-color': '#92141c', 'color': '#767975'});",
#   "}")
)
DT::datatable(tidyLyricscount,
caption = "Table 2: Word frequency across all of AFI's major album releases (with stop-words removed).",
colnames=c("Word","Frequency"))
DT::datatable(tidyLyricscount,
caption = "Table 2: Word frequency across all of AFI's major album releases (with stop-words removed).",
colnames=c("Word","Frequency"))
tidyLyricscount<-tidyLyrics %>%
count(word, sort = TRUE)
DT::datatable(tidyLyricscount,
caption = "Table 2: Word frequency across all of AFI's major album releases (with stop-words removed).",
colnames=c("Word","Frequency"))
```{r}
```{r}
```{r}
```{r}
```{r}
View(tidyLyrics)
```{r}
```{r}
View(tidyLyrics)
```{r}
```{r}
tidyLyrics
```{r}
```{r}
```{r}
tidyLyricscount1<- tidyLyrics %>%
count(word, sort = TRUE)
tidyLyricscount1<- tidyLyrics %>%
count(album,word, sort = TRUE)
View(tidyLyricscount1)
tidyLyricscount1<- tidyLyrics %>%
count(song_name,word, sort = TRUE)
tidyLyricscount1
row.names(AFI_df_song_split)
plot_tidyLyrics<-tidyLyrics_select %>%
bind_tf_idf(word,song_name,n) %>%
mutate(album=factor(album,levels=album_major_release))
row.names(AFI_songs_df_split)
DT::datatable(top_themes,
fillContainer=TRUE)
```
DT::datatable(top_themes,
fillContainer=TRUE)
```
DT::datatable(top_themes,
fillContainer=TRUE)
```
DT::datatable(top_themes,
fillContainer=TRUE)
```
```{r}
#| include: false
#| echo: false
library(cluster)
library(tm)
library(LSAfun)
library(lsa)
# Run LSA on wegihted matrix TDM2.
# Number of dimensions chosen by default with dimcalc_share()
# lsa transformed TDM2 into three matrices and placed them all into the miniLSAspace object
# tk = term matrix, dk = document matrix, and sk = singular value matrix
miniLSAspace<-lsa(TDM2,dims=dimcalc_share())
# View matrix by transforming SVD matrix into text matrix
as.textmatrix(miniLSAspace)
# Doesn't work.  Needs other non-working script.
# findFreqTerms(TDM2)
# these are all unrotated "loadings", like PCA or factor analysis
# This command will show the value-weighted matrix of Terms
# factoring of terms, # factors = 40, so there are 40 factors with loadings for each term
tk2=t(miniLSAspace$sk*t(miniLSAspace$tk))
tk2_round<-round(tk2,2)
DT::datatable(tk2_round,
fillContainer=TRUE)
tk2_round_df<-as.data.frame(tk2_round)
word<-sapply(tk2_round_df,function(x) head(row.names(tk2_round_df)[order(x,decreasing=TRUE)],5))
value<-sapply(tk2_round_df,function(x) head(x[order(x,decreasing=TRUE)],5))
top_themes<-cbind(word,value)
DT::datatable(top_themes,
fillContainer=TRUE)
#| include: false
#| echo: false
library(cluster)
library(tm)
library(LSAfun)
library(lsa)
# Run LSA on wegihted matrix TDM2.
# Number of dimensions chosen by default with dimcalc_share()
# lsa transformed TDM2 into three matrices and placed them all into the miniLSAspace object
# tk = term matrix, dk = document matrix, and sk = singular value matrix
miniLSAspace<-lsa(TDM2,dims=dimcalc_share())
# View matrix by transforming SVD matrix into text matrix
as.textmatrix(miniLSAspace)
# Doesn't work.  Needs other non-working script.
# findFreqTerms(TDM2)
# these are all unrotated "loadings", like PCA or factor analysis
# This command will show the value-weighted matrix of Terms
# factoring of terms, # factors = 40, so there are 40 factors with loadings for each term
tk2=t(miniLSAspace$sk*t(miniLSAspace$tk))
tk2_round<-round(tk2,2)
DT::datatable(tk2_round,
fillContainer=TRUE)
tk2_round_df<-as.data.frame(tk2_round)
word<-sapply(tk2_round_df,function(x) head(row.names(tk2_round_df)[order(x,decreasing=TRUE)],5))
value<-sapply(tk2_round_df,function(x) head(x[order(x,decreasing=TRUE)],5))
top_themes<-cbind(word,value)
DT::datatable(top_themes,
fillContainer=TRUE)
View(lda_topics)
word<-sapply(tk2_round_df,function(x) head(row.names(tk2_round_df)[order(x,decreasing=TRUE)],5))
word<-sapply(tk2_round_df,function(x) head(row.names(tk2_round_df)[order(x,decreasing=TRUE)],5))
DT::datatable(tk2_round,
fillContainer=TRUE)
tk2_round_df<-as.data.frame(tk2_round)
