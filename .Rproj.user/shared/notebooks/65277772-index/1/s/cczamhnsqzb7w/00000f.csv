"0","#| freeze: false"
"0","#| echo: false"
"0","#| include: false"
"0","#| cache: true"
"0","# Next I will follow a more practical example so I can learn how to interpret the output better, besides a wordcloud"
"0","# Also, make sure that all from major albumreleases are included and others are excluded (didn't seem to be the case for some reason)"
"0","# Load required code libraries"
"0","library(cluster)"
"0","library(tm)"
"0","library(LSAfun)"
"0","library(lsa)"
"0","dir = 'C:/Users/caleb/OneDrive/Caleb/Personal/Financials/Curriculum Vitae/Blog'"
"0","setwd(dir)"
"2","Warning: The working directory was changed to C:/Users/caleb/OneDrive/Caleb/Personal/Financials/Curriculum Vitae/Blog inside a notebook chunk. The working directory will be reset when the chunk is finished running. Use the knitr root.dir option in the setup chunk to change the working directory for notebook chunks."
"0","# Create text matrix using tm's DirSource."
"0",""
"0","# Create corpus in memory "
"0","# There's some mistyped code that doesn't work in this paper"
"0","# raw_corpus<-VCorpus(source_dir,readerControl-list(language='en'))"
"0","#I'll copy and paste from previous example to create a raw corpus"
"0","# Establish source directory for all text files. (one .txt file = 1 song)"
"0","source_dir<-paste0(dir,""/AFIsongs/"")"
"0",""
"0","data(stopwords_en)"
"0",""
"0","# Create TDM (text document matrix) with each txt file equal to one document"
"0","TDM<-textmatrix(source_dir,stopwords=c(stopwords_en),stemming=TRUE,"
"0","                 removeNumber=F,minGlobFreq=1.75)"
"0","# TDM #  view TDM"
"0","TDM_summary<-summary.textmatrix(TDM)"
"0","TDM_summary_terms<-t(TDM_summary[""vocabulary""])"
"0","TDM_summary_docs<-t(TDM_summary[""documents""])"
"0",""
"0","# Before running the SVM, create a weighted matrix TDM2."
"0","# TDM2 is term frequency x inverse document frequency (this is a standard method)"
"0","# lw = local weighting, more importance to terms that appear more times within a single document"
"0","# gw = global weighting, less importance to w9rds that appear in more document (same reasoning as removing stop words)"
"0","TDM2 <-lw_tf(TDM)*gw_idf(TDM)"
"0","# TDM2"
